<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>ArUco Class API</title>
    <style>
        body, html { margin: 0; padding: 0; width: 100%; height: 100%; background: #000; overflow: hidden; font-family: monospace; }
        
        #ui {
            position: absolute; top: 0; left: 0; width: 100%; z-index: 10;
            background: rgba(0,0,0,0.6); color: #0f0; padding: 5px;
            pointer-events: none; text-align: center;
        }
        
        #btn-container { pointer-events: auto; margin-bottom: 5px; }
        
        button { 
            padding: 15px 30px; font-size: 16px; 
            background: #007bff; color: white; font-weight: bold;
            border: none; border-radius: 5px; cursor: pointer;
        }
        
        #log { 
            font-size: 11px; max-height: 120px; 
            overflow-y: auto; padding: 5px; text-align: left;
            border-top: 1px solid #444; color: #ccffcc;
        }

        #container { position: relative; width: 100%; height: 100%; display: flex; justify-content: center; align-items: center; background: #222; }
        
        video { 
            position: absolute; top: 0; left: 0; 
            width: 100%; height: 100%; 
            object-fit: cover; opacity: 0.01; z-index: 1;
        }
        
        canvas { 
            position: absolute; top: 0; left: 0; 
            width: 100%; height: 100%; 
            object-fit: contain; z-index: 2; 
        }
    </style>
</head>
<body>

<div id="ui">
    <div id="log">Cargando librerías...</div>
    <div id="btn-container">
        <button id="btnStart" disabled>Espere...</button>
    </div>
</div>

<div id="container">
    <video id="videoInput" playsinline webkit-playsinline autoplay muted></video>
    <canvas id="canvasOutput"></canvas>
</div>

<script async src="https://docs.opencv.org/4.8.0/opencv.js" onload="onCvLoaded()"></script>

<script>
    const logDiv = document.getElementById('log');
    function log(msg) { console.log(msg); logDiv.innerHTML = `> ${msg}<br>` + logDiv.innerHTML; }

    let video = document.getElementById('videoInput');
    let canvas = document.getElementById('canvasOutput');
    let btnStart = document.getElementById('btnStart');
    
    let stream = null;
    let streaming = false;
    
    // Variables OpenCV
    let cap = null;
    let src = null;
    let gray = null;
    let dictionary = null;
    let params = null;
    let detector = null; // NUEVO: El objeto detector
    let markerIds = null;
    let markerCorners = null;
    let rejected = null;

    function onCvLoaded() {
        log("OpenCV 4.8.0 Cargado.");
        btnStart.innerText = "INICIAR PRUEBA ARUCO";
        btnStart.disabled = false;
        btnStart.onclick = startCamera;
    }

    async function startCamera() {
        btnStart.style.display = 'none';
        log("Accediendo a cámara...");
        
        try {
            const constraints = { 
                video: { facingMode: 'environment' }, 
                audio: false 
            };
            stream = await navigator.mediaDevices.getUserMedia(constraints);
            video.srcObject = stream;
            
            await video.play();
            
            log("Video activo. Esperando dimensiones...");
            waitForVideoSize();

        } catch (err) {
            log("ERROR CÁMARA: " + err.message);
            btnStart.style.display = 'inline-block';
        }
    }

    function waitForVideoSize() {
        if (video.videoWidth > 0 && video.videoHeight > 0) {
            log(`Dimensión detectada: ${video.videoWidth}x${video.videoHeight}`);
            startOpenCV();
        } else {
            requestAnimationFrame(waitForVideoSize);
        }
    }

    function startOpenCV() {
        streaming = true;
        
        // 1. Sincronizar tamaños
        video.width = video.videoWidth;
        video.height = video.videoHeight;
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        // 2. Crear Mats
        cap = new cv.VideoCapture(video);
        src = new cv.Mat(video.videoHeight, video.videoWidth, cv.CV_8UC4);
        gray = new cv.Mat();
        
        // 3. CONFIGURACIÓN ARUCO (NUEVA API DE CLASES)
        // Paso A: Obtener diccionario (sin new)
        dictionary = cv.getPredefinedDictionary(cv.DICT_ARUCO_ORIGINAL);
        
        // Paso B: Crear parámetros
        params = new cv.aruco_DetectorParameters();
        
        // Paso C: Crear EL DETECTOR (Esto reemplaza a la función detectMarkers)
        // La clase se llama aruco_ArucoDetector
        try {
            detector = new cv.aruco_ArucoDetector(dictionary, params);
            log("Detector ArUco creado correctamente.");
        } catch(e) {
            log("Error creando ArucoDetector: " + e);
            return;
        }
        
        markerIds = new cv.Mat();
        markerCorners = new cv.MatVector();
        rejected = new cv.MatVector();
        
        log("Sistema listo. Buscando marcadores...");
        requestAnimationFrame(processFrame);
    }

    function processFrame() {
        if (!streaming) return;

        try {
            // Protección contra cambio de tamaño
            if (video.videoWidth !== src.cols || video.videoHeight !== src.rows) {
                video.width = video.videoWidth;
                video.height = video.videoHeight;
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
                src.delete();
                src = new cv.Mat(video.videoHeight, video.videoWidth, cv.CV_8UC4);
                // Si cambiamos src, quizás debamos reiniciar cap? Generalmente VideoCapture se adapta
                // pero por seguridad, reasignamos tamaño.
            }

            cap.read(src);
            cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);

            // --- NUEVA LLAMADA DE DETECCIÓN ---
            // Usamos el objeto 'detector', no la función global 'cv'
            detector.detectMarkers(gray, markerCorners, markerIds, rejected);

            if (markerIds.rows > 0) {
                // Dibujar (Esto sigue siendo una función global de utilidad)
                cv.drawDetectedMarkers(src, markerCorners, markerIds, new cv.Scalar(0, 255, 0, 255));
                
                // Opcional: Mostrar ID en el log solo si cambia (para no saturar)
                // log("ID Detectado: " + markerIds.data32S[0]);
            }
            
            cv.imshow('canvasOutput', src);

            requestAnimationFrame(processFrame);

        } catch (err) {
            log("Error Loop: " + err);
            // Intentar seguir
            requestAnimationFrame(processFrame);
        }
    }
</script>
</body>
</html>
