<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>ArUco Robust Mobile</title>
    <style>
        body, html { margin: 0; padding: 0; width: 100%; height: 100%; background: #000; overflow: hidden; font-family: monospace; }
        
        #ui {
            position: absolute; top: 0; left: 0; width: 100%; z-index: 10;
            background: rgba(0,0,0,0.6); color: #0f0; padding: 5px;
            pointer-events: none;
        }
        
        #btn-container { pointer-events: auto; text-align: center; margin-bottom: 5px; }
        
        button { 
            padding: 12px 24px; font-size: 16px; 
            background: #007bff; color: white; 
            border: none; border-radius: 5px; cursor: pointer;
        }
        
        #log { 
            font-size: 11px; max-height: 100px; 
            overflow-y: auto; padding: 5px; 
            border-top: 1px solid #444; color: #ccffcc;
        }

        #container { position: relative; width: 100%; height: 100%; display: flex; justify-content: center; align-items: center; background: #222; }
        
        /* Video invisible para el usuario, pero con dimensiones reales para OpenCV */
        video { 
            position: absolute; top: 0; left: 0; 
            width: 100%; height: 100%; 
            object-fit: cover; opacity: 0.01; 
            z-index: 1;
        }
        
        canvas { 
            position: absolute; top: 0; left: 0; 
            width: 100%; height: 100%; 
            object-fit: contain; z-index: 2; 
        }
    </style>
</head>
<body>

<div id="ui">
    <div id="btn-container">
        <button id="btnStart" disabled>Cargando Motor...</button>
    </div>
    <div id="log">Inicializando sistema...</div>
</div>

<div id="container">
    <video id="videoInput" playsinline webkit-playsinline autoplay muted></video>
    <canvas id="canvasOutput"></canvas>
</div>

<script async src="https://docs.opencv.org/4.8.0/opencv.js" onload="onCvLoaded()"></script>

<script>
    const logDiv = document.getElementById('log');
    function log(msg) { console.log(msg); logDiv.innerHTML = `> ${msg}<br>` + logDiv.innerHTML; }

    let video = document.getElementById('videoInput');
    let canvas = document.getElementById('canvasOutput');
    let btnStart = document.getElementById('btnStart');
    
    let stream = null;
    let streaming = false;
    
    // Variables OpenCV globales
    let cap = null;
    let src = null;
    let gray = null;
    let dictionary = null;
    let markerIds = null;
    let markerCorners = null;
    let params = null;
    let rejected = null;

    function onCvLoaded() {
        log("OpenCV Cargado.");
        btnStart.innerText = "INICIAR CÁMARA";
        btnStart.disabled = false;
        btnStart.onclick = startCamera;
    }

    async function startCamera() {
        btnStart.style.display = 'none';
        log("Solicitando cámara trasera...");
        
        try {
            const constraints = { 
                video: { facingMode: 'environment' }, 
                audio: false 
            };
            stream = await navigator.mediaDevices.getUserMedia(constraints);
            video.srcObject = stream;
            
            // Promesa de play explícita
            await video.play();
            
            log("Video corriendo. Sincronizando tamaño...");
            
            // Iniciamos el bucle de comprobación de tamaño
            waitForVideoSize();

        } catch (err) {
            log("ERROR AL INICIAR: " + err.message);
            btnStart.style.display = 'inline-block';
        }
    }

    function waitForVideoSize() {
        // Esperamos a que el video tenga dimensiones válidas
        if (video.videoWidth > 0 && video.videoHeight > 0) {
            log(`Dimensiones iniciales: ${video.videoWidth}x${video.videoHeight}`);
            startOpenCV();
        } else {
            requestAnimationFrame(waitForVideoSize);
        }
    }

    function startOpenCV() {
        streaming = true;
        
        // 1. Configuramos los atributos físicos del elemento video
        // IMPORTANTE: Esto evita el error "bad size" inicial
        video.width = video.videoWidth;
        video.height = video.videoHeight;
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        // 2. Inicializamos objetos
        cap = new cv.VideoCapture(video);
        src = new cv.Mat(video.videoHeight, video.videoWidth, cv.CV_8UC4);
        gray = new cv.Mat();
        
        // Diccionario ORIGINAL
        dictionary = cv.getPredefinedDictionary(cv.DICT_ARUCO_ORIGINAL);
        params = new cv.aruco_DetectorParameters();
        
        markerIds = new cv.Mat();
        markerCorners = new cv.MatVector();
        rejected = new cv.MatVector();
        
        log("Sistema ArUco Activo.");
        requestAnimationFrame(processFrame);
    }

    function processFrame() {
        if (!streaming) return;

        try {
            // --- BLOQUE CRÍTICO: GESTIÓN DE REDIMENSIÓN ---
            // Si el video cambia de resolución (giro de pantalla o ajuste automático)
            // las dimensiones no coincidirán y OpenCV lanzará error.
            if (video.videoWidth !== src.cols || video.videoHeight !== src.rows) {
                log(`Cambio de resolución detectado: ${video.videoWidth}x${video.videoHeight}`);
                
                // 1. Actualizar atributos HTML para que VideoCapture lea bien
                video.width = video.videoWidth;
                video.height = video.videoHeight;
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;

                // 2. Recrear matrices con el nuevo tamaño
                src.delete();
                gray.delete();
                src = new cv.Mat(video.videoHeight, video.videoWidth, cv.CV_8UC4);
                gray = new cv.Mat(video.videoHeight, video.videoWidth, cv.CV_8UC1);
            }
            // ----------------------------------------------

            // Leer frame
            cap.read(src);
            
            // Procesar
            cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
            cv.detectMarkers(gray, dictionary, markerCorners, markerIds, params, rejected);

            // Dibujar
            if (markerIds.rows > 0) {
                cv.drawDetectedMarkers(src, markerCorners, markerIds, new cv.Scalar(0, 255, 0, 255));
            }
            
            cv.imshow('canvasOutput', src);

            // Limpieza temporal obligatoria
            // Nota: No borramos src/gray aquí, solo lo que se regenera
            // rejected se limpia automáticamente al sobrescribirse o deberíamos limpiarlo si crece mucho, 
            // pero en JS MatVector suele gestionarse bien en scope corto. 
            // Para seguridad en loops largos:
            // rejected.delete(); rejected = new cv.MatVector(); // (Opcional si notamos lentitud)

            requestAnimationFrame(processFrame);

        } catch (err) {
            log("Error Loop: " + err);
            // Intentar recuperar en el siguiente frame
            requestAnimationFrame(processFrame);
        }
    }
</script>
</body>
</html>
